{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58e2ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Prep\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Pandas\n",
    "- Sklearn\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Be familiar with some common data prep tools: standardizing, scaling, feature encoding\n",
    "- Be able to construct a sklearn pipeline that does data preparation work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448d57e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data cleaning\n",
    "\n",
    "- It is often said that more than 90% of a data scientist's time is spent preparing data\n",
    "- That's likely an underestimate\n",
    "- In order to derive useful results from a model, you need to feed the model useful data\n",
    "- As the saying goes \"Garbage in, garbage out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab944b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Start early\n",
    "\n",
    "- The data preparation process begins before any data is actually collected!\n",
    "- Being part of experiment design or the data collection process is first best\n",
    "- When this is not possible, knowing as much as possible about data source will help\n",
    "    - Identify potential biases    \n",
    "    - Gain intuition on relationships between data\n",
    "    - Know what data *isn't* there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67571e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Types of data manipulation\n",
    "\n",
    "- Once you have some data and have decided what to model, you will likely need to prepare that data for the model\n",
    "- Some common transformations include:\n",
    "    - Standariding or scaling the data\n",
    "    - Feature encoding: one-hot-encoding, ordinal encoding, discritization\n",
    "    - Handling missing data: imputation, filtering, \n",
    "    - Feature engineering: polynomial features, other non-linear transforms\n",
    "- sklearn provides tools for all these types of pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8d80a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Pipelines\n",
    "\n",
    "In sklearn there are two core parent classes\n",
    "\n",
    "1. `Transformers`: transform from $X$ to $\\hat{X}$\n",
    "    - `.fit(X)`: performs necessary calculations to do transformation (stores results)\n",
    "    - `.transform(X)`: does transform of $X$ to $\\hat{X}$\n",
    "1. `Estimators`: Given $X$ and $y$ data (or just $X$ for unsupervised) find model *parameters*\n",
    "    - `.fit(X, y)`: compute parameters of model\n",
    "    - `.predict(X)`: compute predicted $y$'s based on $X$'s that are passed in\n",
    "    \n",
    "> Note `.fit_transform(X)` is shorthand for first fitting, then transforming. Similarly `.fit_predict` will first fit and then generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34849d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### `sklearn.pipeline`\n",
    "\n",
    "- Many ML tasks require multiple steps of preprocessing before passing data to model\n",
    "- These are represented as transformers\n",
    "- A pipeline is a 0 or more transformers and then a single Estimator\n",
    "- Data is passed through transformers, in the order specified, then to estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42083ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### pipeline lifecycle\n",
    "\n",
    "1. Define the pipeline `model = sklearn.pipeline.make_pipeline([trans1, trans2, ..., transN, est])`\n",
    "2. Fit the model: `model.fit(X, y)`. Looks like this:\n",
    "```python\n",
    "X1 = trans1.fit_transform(X)\n",
    "X2 = trans2.fit_transform(X1)\n",
    "# ...\n",
    "XN = transN.fit_transform(XNm)\n",
    "est.fit(XN, y)\n",
    "```\n",
    "3. Generate predictions: `model.predict(x)`:\n",
    "```python\n",
    "x1 = trans1.transform(x)\n",
    "x2 = trans2.transform(x1)\n",
    "# ...\n",
    "xn = transN.transform(xNm)\n",
    "yhat = est.predict(xn)\n",
    "```\n",
    "\n",
    "> pipelines save you the hassle of calling `.fit` and `.transform` on all the transformers every time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde265b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46084182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, pipeline, linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc17fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some dummy data\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "y = np.array([0.1, -2.3, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b1077a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and fit transformer\n",
    "trans1 = preprocessing.PolynomialFeatures(degree=3)\n",
    "trans1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51eca89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1., -1.,  2.,  1., -1.,  2.,  1., -2.,  4.,  1., -1.,  2.,\n",
       "         1., -2.,  4., -1.,  2., -4.,  8.],\n",
       "       [ 1.,  2.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., -1.,  0.,  0., -0.,  1., -1.,  1.,  0.,  0., -0.,\n",
       "         0., -0.,  0.,  1., -1.,  1., -1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply transformation to training data\n",
    "X1 = trans1.transform(X_train)\n",
    "print(X1.shape)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271e698f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define and fit linear model, using transformed data\n",
    "linreg = linear_model.LinearRegression()\n",
    "linreg.fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b626c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1, -2.3,  1.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on training set\n",
    "linreg.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6661f9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's try to evaluate on a test dataset\n",
    "X_test = np.array([[2, 3, 1], [-1, -1, 0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ab90f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f6c0b2714ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# easy to go wrong...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[1;32m    222\u001b[0m                                dense_output=True) + self.intercept_\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 3)"
     ]
    }
   ],
   "source": [
    "# easy to go wrong...\n",
    "linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e66e02",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to transform first...\n",
    "X_test2 = trans1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "441de0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22770181,  1.06545001])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... then we can predict\n",
    "linreg.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd33e32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=3)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easier to set up in a pipeline\n",
    "model = pipeline.make_pipeline(trans1, linreg)\n",
    "\n",
    "# single call to fit\n",
    "model.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f362f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. ,  3. ,  1. ],\n",
       "       [-1. , -1. ,  0.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f76053c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22770181,  1.06545001])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single call to predict\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11015e",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "- Many machine learning algorithms require data to be scaled\n",
    "- Sometimes, the underlying math will even assume features `X` are distributed N(0, 1)\n",
    "- `sklearn.preprocessing.StandardScaler` is a routine to make each feature have mean 0 and variance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8765645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"https://css-materials.s3.amazonaws.com/ML/linear_models_2/insurance_claims_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers = df.select_dtypes([float, int])\n",
    "df_strings = df.select_dtypes([object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_numbers),\n",
    "    index=df_numbers.index,columns=df_numbers.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f3134",
   "metadata": {},
   "source": [
    "Notice mean and std are now (0,1) for all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d2015",
   "metadata": {},
   "source": [
    "Further Reference: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60326054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "31582b9feba862c420bc95ad7fac43fb721c474490d1710b4e50ac63470f9531"
  },
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
